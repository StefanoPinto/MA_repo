---
title: "Stefano MA PCA approach"
output:
  html_document:
    toc: TRUE
    toc_depth: 5
    fig_caption: TRUE
    theme: cosmo
    highlight: breezedark
    code_folding: show
    fontsize: 40px
  date: "`r format(Sys.time(), '%d %B %Y')`"
editor_options: 
  chunk_output_type: console
---  

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(class.output = "code-background")
```

```{css, echo = FALSE}
.code-background {
  background-color: lightblue;
  border: 3px solid silver;
  font-weight: bold;
}

```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(naniar)
library(countrycode)
library(psych)
library(weights)
```

```{r}
theme_set(theme_bw(base_size = 18))
```

- Quick function to select the relevant variables, and set NAs

```{r}
select_and_clean <- function(dataset) {
  dataset_clean <- dataset |> 
    select(essround, cntry, imbgeco, imueclt, imwbcnt, anweight, pspwght, pweight) |> 
    replace_with_na(replace = list(
      imbgeco = c(77, 88, 99),
      imueclt = c(77, 88, 99),
      imwbcnt = c(77, 88, 99))) |> 
    mutate(essround = 2000 + 2 * essround) |> 
    na.omit()
    
  return(dataset_clean)
}
```

```{r, message=FALSE}
data <- read_csv("data2.csv")

data <- data |> select_and_clean()|>
  rename(country = cntry)
```

- We want to use `anweight` as weighting variable
- In some rounds, `anweight` is missing - but we can easily calculate it by multiplying `pspwght` with `pweight` (https://www.europeansocialsurvey.org/sites/default/files/2023-06/ESS_weighting_data_1_1.pdf page 6)

```{r}
data <- data |> 
  mutate(anweight = pspwght * pweight)
```

-  Fixing country codes ("DE" -> "Germany" etc.)

```{r}
data <- data |> 
  mutate(country = countrycode(sourcevar = country,
                             origin = "iso2c",
                             destination = "country.name.en"),
         .keep = "unused")

data[which(is.na(data$country)), "country"] <- "Kosovo"
```

- Now the weighted PCA
- The main idea is to create the correlation matrix using the weights, resulting in the weighted correlation matrix (duh), based on which we do the PCA

```{r}
weighted_pca <- function(dat) {
  
  weights <- dat$anweight
  
  dat_sub <- dat |> 
  select(imbgeco, imueclt, imwbcnt) |> 
  # centering and scaling using weighted mean and square root of weighted variance
  map_df(\(var) var - weighted.mean(var, weights)) |>  
  map_df(\(var) var / sqrt(wtd.var(var, weights))) 

  # weighted correlation matrix using wtd.cors()
  weighted_cor_matrix <- wtd.cors(dat_sub, weight = weights)

  # princomp() [unlike prcomp()] lets us specify a correlation matrix
  # So this is a PCA using the weighted correlation matrix
  pca_result <- princomp(covmat = weighted_cor_matrix, cor = T) 
  
  return(pca_result)
}

```

- We create a DF containing all round - country combinations which we later loop through in order to do a PCA for each (available) combination

```{r}
pca_df <- expand_grid(country = unique(data$country), essround = unique(data$essround))

head(pca_df)
tail(pca_df)
```

```{r}
pca_list <- vector("list", nrow(pca_df))

# One PCA for each country-round combination
# E.g., Austria 2002, Austria 2008, Belgium 2002, ....
# If the particular country-round combination is not available, return NA
for(i in 1:nrow(pca_df)) {
  
  country_temp <- pca_df[i,]$country
  round_temp <- pca_df[i,]$essround
  
  sub_df <- data |> filter(country == country_temp, essround == round_temp)
  
  tryCatch(
    {pca_list[[i]] <- weighted_pca(sub_df)},
    error = function(e) {pca_list[[i]] <- NA}
  )
}

```

- Now, we have a list with each entry corresponding to one row of pca_df

```{r}
pca_list[[1]] # Austria 2002
pca_list[[2]] # Austria 2008, for example, was not available
```

- Functions for the PCA objects contained in pca_list

```{r}
# Function to get the loadings of PC1
# for imbgeco, imueclt & imwbcnt
get_loadings <- function(pca_obj) {
  
  if(is.null(pca_obj)) {
    return(NA)
  }
  
  var_loadings <- pca_obj$loadings[1:3,]
  
  loadings_pc1 <- var_loadings |> 
  as.data.frame() |> 
  rownames_to_column("variable") |> 
  as_tibble() |> 
  rename(PC1 = Comp.1, PC2 = Comp.2, PC3 = Comp.3) |> 
  pull(PC1)
  
  return(tibble(loading_pc1_imbgeco = loadings_pc1[1], loading_pc1_imueclt = loadings_pc1[2], loading_pc1_imwbcnt = loadings_pc1[3]))
}
```

```{r}
res <- pca_list |> 
  map(\(x) get_loadings(x)) 

# Replace the NULL values with DFs where everything is NA
for(i in 1:length(res)) {
  if(any(is.na(res[[i]]))) {
    res[[i]] <- tibble(loading_pc1_imbgeco = NA, loading_pc1_imueclt = NA, loading_pc1_imwbcnt = NA)
  }
}

# Turn to Data Frame
loadings_df <- bind_rows(res)

```

```{r}
# Function to get the explained variance of PC1 for a given pca object
get_explained_variance_pc1 <- function(pca_obj) {
  
  if(is.null(pca_obj)) {
    return(NA)
  }
  
  explained_variance <- pca_obj$sdev^2 / sum(pca_obj$sdev^2)
  names(explained_variance) <- c("PC1", "PC2", "PC3")
  
  explained_variance <- explained_variance |> 
  as.data.frame() |> 
  rownames_to_column("PC") |> 
  as_tibble() |> 
  filter(PC == "PC1") |> 
  pull(explained_variance)
  
  return(explained_variance)
}
```

```{r}
expl_var_pc1 <- map_dbl(pca_list, get_explained_variance_pc1)
head(expl_var_pc1)

```

```{r}
pca_df <- pca_df |> 
  bind_cols(loadings_df) |> 
  mutate(expl_var_pc1 = expl_var_pc1) 
```

- Let check whether we again have that "flipping direction" problem of PC1

```{r, fig.dim=c(10,10)}
pca_df |> 
  # some example countries
  filter(country %in% c("Germany", "Italy", "Hungary")) |> 
  pivot_longer(cols = c(loading_pc1_imbgeco, loading_pc1_imueclt, loading_pc1_imwbcnt)) |> 
  ggplot(aes(name, value)) +
  geom_col(position = "dodge", fill = "steelblue") +
  facet_grid(essround~country) +
  coord_flip() +
  labs(x = "Metric")
```

- Apparently not. interesting. PC1 still seems to represent a general migration attitude.


- The values are again stable over time:

```{r, fig.dim=c(14,14)}
pca_df |> 
  pivot_longer(cols = c(loading_pc1_imueclt, loading_pc1_imbgeco, loading_pc1_imwbcnt)) |> 
  ggplot(aes(essround, value)) +
  geom_line(aes(col = name), lwd = 1) +
  facet_wrap(~country, ncol = 5) +
  theme(legend.position = "bottom") +
  guides(color = guide_legend(override.aes = list(lwd = 3, size = 3)))
```

- We again have quite consistent loading values between 0.52 and 0.60 which is very similar to the results from the captstone project

```{r}
# Slopes of linear model explained variance of PC1 vs. round
# 39 countries, 39 slopes
countries <- unique(pca_df$country)
slopes <- c()

for(i in 1:length(countries)) {
  sub_df <- pca_df |> 
    filter(country == countries[i])
  
  mod <- lm(expl_var_pc1 ~ essround, data = sub_df)
  slope <- coef(mod)[2]
  slopes[i] <- slope
}
  
slopes_df <- tibble(country = countries, slope_expl_var_pc1 = slopes)

``` 

- We look at the explained variance of PC1, and find that it is again 70 - 75 % in most cases

```{r, fig.dim=c(10,10)}
pca_df |> 
  ggplot(aes(essround, expl_var_pc1)) +
  geom_col(fill = "darkblue") +
  facet_wrap(~country, ncol = 5) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Year", y = "Explained variance of PC1")
```

- We also look at the **slope** of the explained variance of PC1

```{r, fig.dim=c(10,10)}
ggplot(na.omit(slopes_df), aes(fct_reorder(country, slope_expl_var_pc1), slope_expl_var_pc1)) +
  geom_col() +
  coord_flip() +
  labs(x = "", y = "Slope of explained variance of PC1") 
```

- Also looks very similar to its counterpart from the capstone project with italy at the top. That's good. ðŸ˜Ž                


```{r}
write_csv(pca_df, "pca_metric_loadings_variance.csv")
write_csv(slopes_df, "pca_metric_slope_variance.csv")
```



























